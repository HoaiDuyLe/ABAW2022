{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc46428b",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set_Edit\"):\n",
    "    os.makedirs(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set_Edit\")\n",
    "if not os.path.exists(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set_Edit\"):\n",
    "    os.makedirs(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set_Edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = glob.glob(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set/*\")\n",
    "data_val = glob.glob(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3472ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_train)):\n",
    "    with open(data_train[i], 'r') as fr :\n",
    "        lines = fr.readlines()\n",
    "    with open(data_train[i].replace(\"Train_Set\",\"Train_Set_Edit\"), 'w') as fw:\n",
    "        for line in lines:\n",
    "            if not \"-1\" in line:\n",
    "                fw.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_val)):\n",
    "    with open(data_val[i], 'r') as fr :\n",
    "        lines = fr.readlines()\n",
    "    with open(data_val[i].replace(\"Validation_Set\",\"Validation_Set_Edit\"), 'w') as fw:\n",
    "        for line in lines:\n",
    "            if not \"-1\" in line:\n",
    "                fw.write(\"%s\" % line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0d7cf",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99716aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = glob.glob(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set_Edit/*\")\n",
    "data_val = glob.glob(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set_Edit/*\")\n",
    "exclude_list = ['10-60-1280x720.txt','10-60-1280x720_right.txt','135-24-1920x1080_left.txt', \n",
    "                '135-24-1920x1080_right.txt','46-30-484x360_left.txt','46-30-484x360_right.txt','86-24-1920x1080.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c9e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "stas_train = {'AU1':0, 'AU2':0, 'AU4':0, 'AU6':0, 'AU7':0, 'AU10':0, 'AU12':0, 'AU15':0, 'AU23':0, 'AU24':0, 'AU25':0, 'AU26':0}\n",
    "for i in range(len(data_train)):\n",
    "    if not os.path.basename(data_train[i]) in exclude_list:\n",
    "        df = pd.read_csv(data_train[i], delimiter = \",\")\n",
    "        count+=df.shape[0]\n",
    "        for key, value in stas_train.items():\n",
    "            if not math.isnan(df.apply(pd.value_counts)[key][1]):\n",
    "                stas_train[key] += df.apply(pd.value_counts)[key][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac489a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "stas_val = {'AU1':0, 'AU2':0, 'AU4':0, 'AU6':0, 'AU7':0, 'AU10':0, 'AU12':0, 'AU15':0, 'AU23':0, 'AU24':0, 'AU25':0, 'AU26':0}\n",
    "for i in range(len(data_val)):\n",
    "    df = pd.read_csv(data_val[i], delimiter = \",\")\n",
    "    count+=df.shape[0]\n",
    "    for key, value in stas_val.items():\n",
    "        if not math.isnan(df.apply(pd.value_counts)[key][1]):\n",
    "            stas_val[key] += df.apply(pd.value_counts)[key][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da9206",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(len(stas_train))\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(X, stas_train.values(), width=0.5, color='b', align='center')\n",
    "ax.bar(X-0.5, stas_val.values(), width=0.5, color='g', align='center')\n",
    "ax.legend(('Train','Validation'))\n",
    "plt.xticks(X, stas_train.keys())\n",
    "plt.title(\"AU dataset distribution \", fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278d78e",
   "metadata": {},
   "source": [
    "## Calculate weight for positive and negative sample in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = glob.glob(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set_Edit/*\")\n",
    "data_val = glob.glob(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set_Edit/*\")\n",
    "exclude_list = ['10-60-1280x720.txt','10-60-1280x720_right.txt','135-24-1920x1080_left.txt', \n",
    "                '135-24-1920x1080_right.txt','46-30-484x360_left.txt','46-30-484x360_right.txt','86-24-1920x1080.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3131d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "stas_train = {'AU1':0, 'AU2':0, 'AU4':0, 'AU6':0, 'AU7':0, 'AU10':0, 'AU12':0, 'AU15':0, 'AU23':0, 'AU24':0, 'AU25':0, 'AU26':0}\n",
    "for i in range(len(data_train)):\n",
    "    if not os.path.basename(data_train[i]) in exclude_list:\n",
    "        df = pd.read_csv(data_train[i], delimiter = \",\")\n",
    "        count+=df.shape[0]\n",
    "        for key, value in stas_train.items():\n",
    "            if not math.isnan(df.apply(pd.value_counts)[key][1]):\n",
    "                stas_train[key] += df.apply(pd.value_counts)[key][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weights = []\n",
    "for key, value in stas_train.items():\n",
    "    pos_weights.append(count/(2*value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76314cf5",
   "metadata": {},
   "source": [
    "## Create tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c958ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name = os.listdir(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set_Edit\")\n",
    "val_name = os.listdir(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set_Edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for file in train_name:\n",
    "    df = pd.read_csv(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Train_Set_Edit/\"+file, delimiter = \",\")\n",
    "    image_names = os.listdir(r\"./data/cropped_aligned/\"+file.replace(\".txt\",\"\"))\n",
    "    if len(image_names)!=df.shape[0]:\n",
    "        continue\n",
    "    y_train.extend(np.array(df))\n",
    "    for name in image_names:\n",
    "        if not \"jpg\" in name:\n",
    "            continue\n",
    "        X_train.append(r\"./data/cropped_aligned/\"+file.replace(\".txt\",\"\")+\"/\"+name)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a2ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "for file in val_name:\n",
    "    df = pd.read_csv(r\"./data/Third ABAW Annotations/AU_Detection_Challenge/Validation_Set_Edit/\"+file, delimiter = \",\")\n",
    "    y_val.extend(np.array(df))\n",
    "    image_names = os.listdir(r\"./data/cropped_aligned/\"+file.replace(\".txt\",\"\"))\n",
    "    for name in image_names:\n",
    "        if not \"jpg\" in name:\n",
    "            continue\n",
    "        X_val.append(r\"./data/cropped_aligned/\"+file.replace(\".txt\",\"\")+\"/\"+name)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path,label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (112, 112))\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd68d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices((X_train,y_train))\n",
    "train_dataset = train_loader.shuffle(len(X_train))\n",
    "train_dataset = train_dataset.map(\n",
    "    load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(256)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = tf.data.Dataset.from_tensor_slices((X_val,y_val))\n",
    "val_dataset = val_loader.map(\n",
    "    load_image, num_parallel_calls=tf.data.AUTOTUNE).batch(256)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ffa1b",
   "metadata": {},
   "source": [
    "## Define model and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb89c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_block(filters, kernel_size, input_shape, is_last):\n",
    "    if (input_shape != None):\n",
    "        return tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size,input_shape=input_shape, padding=\"same\", strides=1),\n",
    "            tf.keras.layers.BatchNormalization(axis=-1),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.MaxPool2D((2, 2))])\n",
    "    else:\n",
    "        if is_last:\n",
    "            return tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding=\"same\", strides=1), \n",
    "                tf.keras.layers.BatchNormalization(axis=-1),\n",
    "                tf.keras.layers.ReLU()])\n",
    "        else:\n",
    "            return tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, padding=\"same\", strides=1), \n",
    "                tf.keras.layers.BatchNormalization(axis=-1),\n",
    "                tf.keras.layers.ReLU(),\n",
    "                tf.keras.layers.MaxPool2D((2, 2))])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=(112, 112, 3))\n",
    "    face = cnn_block(32, (3,3), (112,112,3), False)(inputs)\n",
    "    face = cnn_block(64, (3,3), None, False)(face)\n",
    "    face = cnn_block(128, (3,3), None, False)(face)\n",
    "    face = cnn_block(128, (3,3), None, False)(face)\n",
    "    face = cnn_block(256, (3,3), None, False)(face)\n",
    "    face = cnn_block(256, (3,3), None, True)(face)\n",
    "    \n",
    "    N, H, W, C = face.shape\n",
    "    face_vector = tf.keras.layers.Reshape((H * W, C))(face)\n",
    "    attention_weight = tf.keras.layers.Dense(units=128, activation='relu')(face_vector)\n",
    "    attention_weight = tf.keras.layers.BatchNormalization()(attention_weight, training=False)\n",
    "    attention_weight = tf.keras.layers.Activation(\"relu\")(attention_weight)\n",
    "    attention_weight = tf.keras.layers.Dense(units=1, activation=None)(attention_weight)\n",
    "    attention_weight = tf.nn.softmax(attention_weight, axis=1)\n",
    "    face_vector = tf.keras.layers.Dot(axes=1)([face_vector, attention_weight])\n",
    "    face_vector = tf.keras.layers.Reshape((C,))(face_vector)\n",
    "\n",
    "    features = tf.keras.layers.Dense(units=128, activation='relu')(face_vector)\n",
    "    features = tf.keras.layers.Dropout(rate=0.5)(features)\n",
    "    outputs = tf.keras.layers.Dense(12,activation = \"sigmoid\",\n",
    "                                    kernel_regularizer=tf.keras.regularizers.l2(0.005),\n",
    "                                    activity_regularizer=tf.keras.regularizers.l1(0.005))(features)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7847de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_BCE_loss(y_true,y_pred):\n",
    "    loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(labels=y_true, logits=y_pred, pos_weight=tf.constant(pos_weights)), axis=-1)\n",
    "    return loss\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch<6:\n",
    "        return 1e-3\n",
    "    else:\n",
    "        return 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad8440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=weight_BCE_loss,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
    "                       tfa.metrics.F1Score(num_classes=12, average='macro',threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6523c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"./model\" + r\"/saved-model-BCE-{epoch:02d}-{val_f1_score:.4f}.hdf5\"\n",
    "cp_callback = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, monitor=\"val_f1_score\",\n",
    "                                        save_weights_only=True,save_best_only=False, verbose=1),\n",
    "               tf.keras.callbacks.LearningRateScheduler(scheduler)]\n",
    "history = model.fit(train_dataset, validation_data=val_dataset, \n",
    "                    epochs=20, callbacks=cp_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad09914",
   "metadata": {},
   "source": [
    "## Predict on test set for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f208ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=weight_BCE_loss,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(), \n",
    "                       tfa.metrics.F1Score(num_classes=12, average='macro',threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7df0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(r\"./model/saved-model-BCE-03-0.4802.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef351d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_test(results, pwd, img_num):\n",
    "    with open(f'{pwd}.txt', 'w') as file:\n",
    "        file.write(f'id,AU1,AU2,AU4,AU6,AU7,AU10,AU12,AU15,AU23,AU24,AU25,AU26\\n')\n",
    "        for r, n in zip(results, img_num):\n",
    "            file.write(n)\n",
    "            file.write(',')\n",
    "            pred = ','.join([str(_) for _ in r])\n",
    "            file.write(pred)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r\"./data/test_dir\"\n",
    "test_names = os.listdir(test_path)\n",
    "for test_dir in test_names:\n",
    "    croped_dir_list = sorted(os.listdir(f'{test_path}/{test_dir}'))\n",
    "    results = []\n",
    "    img_num = []\n",
    "    for img in tqdm(croped_dir_list):\n",
    "        img_path = f'{test_path}/{test_dir}/{img}'\n",
    "        _,  ext = os.path.splitext(img_path)\n",
    "        if ext != '.jpg':\n",
    "            continue\n",
    "        input_img = tf.io.read_file(img_path)\n",
    "        input_img = tf.image.decode_jpeg(input_img, channels=3)\n",
    "        input_img = tf.image.resize(input_img, (112, 112))\n",
    "        input_img = tf.expand_dims(input_img, 0)\n",
    "        result = model.predict(input_img)\n",
    "        predict = np.where(result[0] > 0.5, 1, 0)\n",
    "        img_num.append(img)\n",
    "        results.append(predict)\n",
    "    predicted_test(results, f'{TARGET_DIR}/{test_dir}', img_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c8450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f3743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
